# -*- coding: utf-8 -*-
"""NFT_Scratch.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ZUmOpIW_GcCYctP5W4hZaHHjqSeGwn0W
"""

!unzip "drive/MyDrive/Helmet_Dataset"

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.optimizers import RMSprop
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from keras_preprocessing import image
import numpy as np
import cv2
import matplotlib.pyplot as plt
import os

model = tf.keras.Sequential([
    tf.keras.layers.Conv2D(16, (3, 3), activation='relu', input_shape=(416, 416, 3)),
    tf.keras.layers.MaxPool2D(2, 2),
    tf.keras.layers.Conv2D(16, (3, 3), activation='relu'),
    tf.keras.layers.MaxPool2D(2, 2),
    tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),
    tf.keras.layers.MaxPool2D(2, 2),
    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),
    tf.keras.layers.MaxPool2D(2, 2),
    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),
    tf.keras.layers.MaxPool2D(2,2),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(4096, activation='relu'),
    tf.keras.layers.Dense(1024, activation='relu'),
    tf.keras.layers.Dense(512, activation='relu'),
    tf.keras.layers.Dense(1, activation='sigmoid')
])

model.summary()

def scheduler(epoch, lr):
  if epoch < 10:
    return lr
  else:
    return lr * tf.math.exp(-0.1)

checkpoint_path = "drive/MyDrive/weights_new.ckpt"
checkpoint_dir = os.path.dirname(checkpoint_path)
my_callbacks=[tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,
                                                 save_weights_only=True,
                                                 verbose=1),
              tf.keras.callbacks.LearningRateScheduler(scheduler)]

model.compile(loss='binary_crossentropy', optimizer=RMSprop(learning_rate=0.01), metrics=['accuracy'])

train_datagen = ImageDataGenerator(rescale=1 / 255, rotation_range=90, horizontal_flip=True, zoom_range=0.5)
validation_datagen = ImageDataGenerator(rescale=1/255)

train_generator = train_datagen.flow_from_directory(
    'DatasetScratch/Training',
    target_size=(416, 416),
    batch_size=5,
    class_mode='binary',
)

validation_generator = validation_datagen.flow_from_directory(
    'DatasetScratch/Testing',
    target_size=(416, 416),
    batch_size=5,
    class_mode='binary'
)

history = model.fit_generator(
    train_generator,
    steps_per_epoch=20,
    epochs=500,
    verbose =1,
    validation_data= validation_generator,
    validation_steps=2,
    callbacks=my_callbacks
)

checkpoint_path = "drive/MyDrive/weights.ckpt"
model.load_weights(checkpoint_path)

base_path="Test_Data/"
images_1=os.listdir(base_path)
print(images_1)
for i in images_1:
  path=base_path+i
  im = cv2.imread(path)
  plt.imshow(cv2.cvtColor(im, cv2.COLOR_BGR2RGB))
  plt.show()

  img = image.load_img( path, target_size=(416,416))
  x = image.img_to_array(img)
  x = np.expand_dims(x,axis=0)

  images = np.vstack([x])
  classes = model.predict(images, batch_size=1)
  print('Classes ', classes)
  if classes[0]>0.5:
    print("The person is wearing a helmet.")
  else:
    print("The person is NOT wearing a helmet.")

